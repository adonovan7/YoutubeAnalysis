{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Comments Sentiment Analysis \n",
    "Spring 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Basic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd; import os\n",
    "import csv; import numpy as np\n",
    "import re; import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/') # change directory\n",
    "os.chdir('/home/sxi/myProjects/dataScience/YoutubeAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv', delimiter=\",\", skiprows=2, encoding='utf-8', engine='python') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Labeled YouTube Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "okgo = pd.read_csv('data/OKGO.csv', delimiter=\";\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "trump = pd.read_csv('data/trump.csv', delimiter=\",\", skiprows=2, encoding='utf-8', error_bad_lines=False, engine='python') \n",
    "swift = pd.read_csv('data/TaylorSwift.csv', delimiter=\",\", skiprows=2, nrows=180, encoding='utf-8', engine='python') \n",
    "royal = pd.read_csv('data/RoyalWedding.csv', delimiter=\",\", skiprows=2, nrows=61, encoding='utf-8', engine='python')\n",
    "paul = pd.read_csv('data/LoganPaul.csv', delimiter=\",\", skiprows=2, nrows=200, encoding='utf-8', engine='python') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-YouTube Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = pd.read_csv('data/Kagel.csv', delimiter=\",\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "tweets = pd.read_csv('data/twitter.csv', delimiter=\",\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "tweets2 = pd.read_csv('data/twitter2.csv', names=['label','tweet_id','date','query','user','comment'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Clean Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(['Topic', 'TweetId', \"TweetDate\"], axis = 1).dropna()\n",
    "tweets.columns = [\"label\", \"comment\"]\n",
    "tweets.label = tweets.label.replace({'positive': '1.0', 'negative':'-1.0', 'neutral': '0.0', 'irrelevant': '0.0'}, regex=True)\n",
    "tweets['label'] = pd.to_numeric(tweets['label'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2 = tweets2.drop(['tweet_id', 'date', 'query','user'], axis = 1).dropna()\n",
    "tweets2['label'] = tweets2['label'].map({0:-1, 2:0, 4:1})\n",
    "tweets2['label'] = pd.to_numeric(tweets2['label'], errors='coerce')\n",
    "for i in range(len(tweets2)):\n",
    "    tweets2.comment[i] = re.sub(r'@.*?(?=\\s)|([^0-9A-Za-z \\t])', '', tweets2.comment[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs.columns = [\"label\", \"comment\"]\n",
    "blogs['label'] = pd.to_numeric(blogs['label'], errors='coerce')\n",
    "okgo = okgo.drop(okgo.columns[[2, 3]], axis =1).dropna()\n",
    "paul = paul.drop([\"Unnamed: 2\"], axis =1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cols(DF):\n",
    "    DF.columns = [\"label\", \"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_cols(okgo)\n",
    "fix_cols(trump)\n",
    "fix_cols(swift)\n",
    "fix_cols(royal)\n",
    "fix_cols(paul)\n",
    "fix_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.b Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.concat([okgo, trump, swift, royal, paul], ignore_index=True)\n",
    "full = pd.concat([okgo, trump, swift, royal, paul, blogs, tweets, tweets2], ignore_index=False)\n",
    "videos_not_okgo = pd.concat([trump, swift, royal, paul], ignore_index=False)\n",
    "videos_not_royal = pd.concat([okgo, trump, swift, paul], ignore_index=False)\n",
    "\n",
    "DataList = [videos, full, videos_not_royal, videos_not_okgo]\n",
    "excluded = [okgo, royal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Based on the comments I see here and on some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Why are we still here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>Keep killing trees for your awsome video mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subscribe to the channel     \"I'MTISHA 24\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I want to believe itÕs a green screen because ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            comment\n",
       "138     1.0  Based on the comments I see here and on some o...\n",
       "2501    0.0                           Why are we still here...\n",
       "348    -1.0  Keep killing trees for your awsome video mothe...\n",
       "1693    0.0         Subscribe to the channel     \"I'MTISHA 24\"\n",
       "992     0.0  I want to believe itÕs a green screen because ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = videos.copy()\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Remove Non-Alphabetic Characters (including numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AsStr(DF):\n",
    "    DF[\"comment\"]= DF[\"comment\"].astype(str) \n",
    "\n",
    "for i in range(0, len(DataList)): \n",
    "    AsStr(DataList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(excluded)): \n",
    "    AsStr(excluded[i])\n",
    "    \n",
    "AsStr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanerFn(b):\n",
    "    for row in range(len(b)):\n",
    "        line = b.loc[row, \"comment\"]\n",
    "        b.loc[row,\"comment\"] = re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "        \n",
    "def cleanerFn2(b):\n",
    "    for row in range(len(b)):\n",
    "        line = b.iloc[row, 1]\n",
    "        b.iloc[row,1] = re.sub(\"[^a-zA-Z]\", \" \", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanerFn(df)\n",
    "cleanerFn2(data)\n",
    "\n",
    "for i in range(0, len(DataList)): \n",
    "    cleanerFn2(DataList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(excluded)): \n",
    "    cleanerFn2(excluded[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sxi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sw = stopwords.words('english')\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['com_token']=df['comment'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Remove Stop Words, Lemmatization, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sxi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlpFunction(DF):\n",
    "    DF['com_token'] = DF['comment'].str.lower().str.split()\n",
    "    DF['com_remv'] = DF['com_token'].apply(lambda x: [y for y in x if y not in sw])\n",
    "    DF[\"com_lemma\"] = DF['com_remv'].apply(lambda x : [lemmatizer.lemmatize(y) for y in x]) # lemmatization\n",
    "    DF['com_stem'] = DF['com_lemma'].apply(lambda x : [ps.stem(y) for y in x]) # stemming\n",
    "    DF[\"com_full\"] = DF[\"com_stem\"].apply(' '.join)\n",
    "    DF[\"com_tagged\"] = DF['comment'].apply(lambda x : [nltk.pos_tag(y) for y in x]) #word tagging\n",
    "    DF[\"com_stem_str\"] = DF[\"com_stem\"].apply(', '.join)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to count bigrams and POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"com_tagged\"] = df['comment'].apply(lambda x : [nltk.pos_tag(y) for y in x]) #word tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andiedonovan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "nltk.download('punkt')\n",
    "\n",
    "texts = df['comment'].tolist()\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_texts\n",
    "df[\"tagged\"] = tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omgidk y but i just cant stop laughinglmao</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is literally not one thing about Krystal...</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Try not to laugh challenge right there</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>httpswwwyoutubecomwatchvKtI40e1cEN4</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label comment com_token\n",
       "0        omgidk y but i just cant stop laughinglmao      nan     [nan]\n",
       "1  There is literally not one thing about Krystal...     nan     [nan]\n",
       "2                                                        nan     [nan]\n",
       "3            Try not to laugh challenge right there      nan     [nan]\n",
       "4               httpswwwyoutubecomwatchvKtI40e1cEN4      nan     [nan]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_token</th>\n",
       "      <th>com_tagged</th>\n",
       "      <th>tagged</th>\n",
       "      <th>com_remv</th>\n",
       "      <th>com_lemma</th>\n",
       "      <th>com_stem</th>\n",
       "      <th>com_full</th>\n",
       "      <th>com_stem_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omgidk y but i just cant stop laughinglmao</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[[(n, NN)], [(a, DT)], [(n, NN)]]</td>\n",
       "      <td>[(nan, NN)]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is literally not one thing about Krystal...</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[[(n, NN)], [(a, DT)], [(n, NN)]]</td>\n",
       "      <td>[(nan, NN)]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[[(n, NN)], [(a, DT)], [(n, NN)]]</td>\n",
       "      <td>[(nan, NN)]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Try not to laugh challenge right there</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[[(n, NN)], [(a, DT)], [(n, NN)]]</td>\n",
       "      <td>[(nan, NN)]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>httpswwwyoutubecomwatchvKtI40e1cEN4</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[[(n, NN)], [(a, DT)], [(n, NN)]]</td>\n",
       "      <td>[(nan, NN)]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label comment com_token  \\\n",
       "0        omgidk y but i just cant stop laughinglmao      nan     [nan]   \n",
       "1  There is literally not one thing about Krystal...     nan     [nan]   \n",
       "2                                                        nan     [nan]   \n",
       "3            Try not to laugh challenge right there      nan     [nan]   \n",
       "4               httpswwwyoutubecomwatchvKtI40e1cEN4      nan     [nan]   \n",
       "\n",
       "                          com_tagged       tagged com_remv com_lemma com_stem  \\\n",
       "0  [[(n, NN)], [(a, DT)], [(n, NN)]]  [(nan, NN)]    [nan]     [nan]    [nan]   \n",
       "1  [[(n, NN)], [(a, DT)], [(n, NN)]]  [(nan, NN)]    [nan]     [nan]    [nan]   \n",
       "2  [[(n, NN)], [(a, DT)], [(n, NN)]]  [(nan, NN)]    [nan]     [nan]    [nan]   \n",
       "3  [[(n, NN)], [(a, DT)], [(n, NN)]]  [(nan, NN)]    [nan]     [nan]    [nan]   \n",
       "4  [[(n, NN)], [(a, DT)], [(n, NN)]]  [(nan, NN)]    [nan]     [nan]    [nan]   \n",
       "\n",
       "  com_full com_stem_str  \n",
       "0      nan          nan  \n",
       "1      nan          nan  \n",
       "2      nan          nan  \n",
       "3      nan          nan  \n",
       "4      nan          nan  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = nlpFunction(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(DataList)): \n",
    "    nlpFunction(DataList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(excluded)): \n",
    "    nlpFunction(excluded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nlpFunction(df)\n",
    "data = nlpFunction(data)\n",
    "trump = nlpFunction(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_token</th>\n",
       "      <th>com_remv</th>\n",
       "      <th>com_lemma</th>\n",
       "      <th>com_stem</th>\n",
       "      <th>com_full</th>\n",
       "      <th>com_tagged</th>\n",
       "      <th>com_stem_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>Everyone knows brand s papers from  But  No on...</td>\n",
       "      <td>[everyone, knows, brand, s, papers, from, but,...</td>\n",
       "      <td>[everyone, knows, brand, papers, one, knows, w...</td>\n",
       "      <td>[everyone, know, brand, paper, one, know, welf...</td>\n",
       "      <td>[everyon, know, brand, paper, one, know, welfa...</td>\n",
       "      <td>everyon know brand paper one know welfar emplo...</td>\n",
       "      <td>[[(E, NN)], [(v, NN)], [(e, NN)], [(r, NN)], [...</td>\n",
       "      <td>everyon, know, brand, paper, one, know, welfar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Your paper cut balance is</td>\n",
       "      <td>[your, paper, cut, balance, is]</td>\n",
       "      <td>[paper, cut, balance]</td>\n",
       "      <td>[paper, cut, balance]</td>\n",
       "      <td>[paper, cut, balanc]</td>\n",
       "      <td>paper cut balanc</td>\n",
       "      <td>[[( , NN)], [(Y, NN)], [(o, NN)], [(u, NN)], [...</td>\n",
       "      <td>paper, cut, balanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>OH SHIT WHEN I SAW THIS ON MY FRONT PAGE      ...</td>\n",
       "      <td>[oh, shit, when, i, saw, this, on, my, front, ...</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>oh shit saw front page love song</td>\n",
       "      <td>[[(O, NN)], [(H, NN)], [( , NN)], [(S, NN)], [...</td>\n",
       "      <td>oh, shit, saw, front, page, love, song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Blowing my mind yet again</td>\n",
       "      <td>[blowing, my, mind, yet, again]</td>\n",
       "      <td>[blowing, mind, yet]</td>\n",
       "      <td>[blowing, mind, yet]</td>\n",
       "      <td>[blow, mind, yet]</td>\n",
       "      <td>blow mind yet</td>\n",
       "      <td>[[(B, NN)], [(l, NN)], [(o, NN)], [(w, NN)], [...</td>\n",
       "      <td>blow, mind, yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Should have gone with Dunder Mifflin</td>\n",
       "      <td>[should, have, gone, with, dunder, mifflin]</td>\n",
       "      <td>[gone, dunder, mifflin]</td>\n",
       "      <td>[gone, dunder, mifflin]</td>\n",
       "      <td>[gone, dunder, mifflin]</td>\n",
       "      <td>gone dunder mifflin</td>\n",
       "      <td>[[(S, NN)], [(h, NN)], [(o, NN)], [(u, NN)], [...</td>\n",
       "      <td>gone, dunder, mifflin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0   -1.0  Everyone knows brand s papers from  But  No on...   \n",
       "1    0.0         Your paper cut balance is                    \n",
       "2    1.0  OH SHIT WHEN I SAW THIS ON MY FRONT PAGE      ...   \n",
       "3    1.0                          Blowing my mind yet again   \n",
       "4    0.0               Should have gone with Dunder Mifflin   \n",
       "\n",
       "                                           com_token  \\\n",
       "0  [everyone, knows, brand, s, papers, from, but,...   \n",
       "1                    [your, paper, cut, balance, is]   \n",
       "2  [oh, shit, when, i, saw, this, on, my, front, ...   \n",
       "3                    [blowing, my, mind, yet, again]   \n",
       "4        [should, have, gone, with, dunder, mifflin]   \n",
       "\n",
       "                                            com_remv  \\\n",
       "0  [everyone, knows, brand, papers, one, knows, w...   \n",
       "1                              [paper, cut, balance]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "3                               [blowing, mind, yet]   \n",
       "4                            [gone, dunder, mifflin]   \n",
       "\n",
       "                                           com_lemma  \\\n",
       "0  [everyone, know, brand, paper, one, know, welf...   \n",
       "1                              [paper, cut, balance]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "3                               [blowing, mind, yet]   \n",
       "4                            [gone, dunder, mifflin]   \n",
       "\n",
       "                                            com_stem  \\\n",
       "0  [everyon, know, brand, paper, one, know, welfa...   \n",
       "1                               [paper, cut, balanc]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "3                                  [blow, mind, yet]   \n",
       "4                            [gone, dunder, mifflin]   \n",
       "\n",
       "                                            com_full  \\\n",
       "0  everyon know brand paper one know welfar emplo...   \n",
       "1                                   paper cut balanc   \n",
       "2                   oh shit saw front page love song   \n",
       "3                                      blow mind yet   \n",
       "4                                gone dunder mifflin   \n",
       "\n",
       "                                          com_tagged  \\\n",
       "0  [[(E, NN)], [(v, NN)], [(e, NN)], [(r, NN)], [...   \n",
       "1  [[( , NN)], [(Y, NN)], [(o, NN)], [(u, NN)], [...   \n",
       "2  [[(O, NN)], [(H, NN)], [( , NN)], [(S, NN)], [...   \n",
       "3  [[(B, NN)], [(l, NN)], [(o, NN)], [(w, NN)], [...   \n",
       "4  [[(S, NN)], [(h, NN)], [(o, NN)], [(u, NN)], [...   \n",
       "\n",
       "                                        com_stem_str  \n",
       "0  everyon, know, brand, paper, one, know, welfar...  \n",
       "1                                 paper, cut, balanc  \n",
       "2             oh, shit, saw, front, page, love, song  \n",
       "3                                    blow, mind, yet  \n",
       "4                              gone, dunder, mifflin  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import itertools\\nfrom nltk.collocations import BigramCollocationFinder\\nfrom nltk.metrics import BigramAssocMeasures\\n \\ndef bigram_word_feats(DF, score_fn=BigramAssocMeasures.chi_sq, n=200):\\n    bigram_finder = BigramCollocationFinder.from_words(DF[\"\"])\\n    bigrams = bigram_finder.nbest(score_fn, n)\\n    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\\n \\nevaluate_classifier(bigram_word_feats)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    " \n",
    "def bigram_word_feats(DF, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(DF[\"\"])\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])\n",
    " \n",
    "evaluate_classifier(bigram_word_feats)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER (Named Entry Recognition) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk.tag import StanfordNERTagger\\nfrom nltk.tokenize import word_tokenize\\n\\nst = StanfordNERTagger(\\'/usr/share/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz\\',\\n                       \\'/usr/share/stanford-ner/stanford-ner.jar\\',\\n                       encoding=\\'utf-8\\')\\n\\ntext = df[\"comments\"]\\n\\ntok_text = word_tokenize(text)\\nst_text = st.tag(tokenized_text)\\n\\nprint(st_text)'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('/usr/share/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                       '/usr/share/stanford-ner/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "text = df[\"comments\"]\n",
    "\n",
    "tok_text = word_tokenize(text)\n",
    "st_text = st.tag(tokenized_text)\n",
    "\n",
    "print(st_text)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn # machine learning\n",
    "from sklearn.model_selection import train_test_split # splitting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'com_stem_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'com_stem_str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0f9936041210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"com_stem_str\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrump\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"com_stem_str\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrump\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"com_stem_str\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'com_stem_str'"
     ]
    }
   ],
   "source": [
    "X_train = data[\"com_stem_str\"]\n",
    "X_test = trump[\"com_stem_str\"]\n",
    "Y_train = data[\"label\"]\n",
    "Y_test = trump[\"label\"]\n",
    "X_user = df[\"com_stem_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = videos.dropna(axis=0)\n",
    "videos_not_okgo = videos_not_okgo.dropna(axis=0)\n",
    "videos_not_royal = videos_not_royal.dropna(axis=0)\n",
    "royal = royal.dropna(axis=0)\n",
    "okgo = okgo.dropna(axis=0)\n",
    "full = full.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_videos, x_test_videos, y_train_videos, y_test_videos = train_test_split(\n",
    "    videos[\"com_stem_str\"], videos[\"label\"], test_size=0.33, random_state=42)\n",
    "\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    full[\"com_stem_str\"], full[\"label\"], test_size=0.33, random_state=42)\n",
    "\n",
    "####\n",
    "x_train_not_okgo = videos_not_okgo[\"com_stem_str\"]\n",
    "x_test_okgo = okgo[\"com_stem_str\"]\n",
    "\n",
    "y_train_not_okgo = videos_not_okgo[\"label\"]\n",
    "y_test_okgo = okgo[\"label\"]\n",
    "\n",
    "####\n",
    "x_train_not_royal = videos_not_royal[\"com_stem_str\"]\n",
    "x_test_royal = royal[\"com_stem_str\"]\n",
    "\n",
    "y_train_not_royal = videos_not_royal[\"label\"]\n",
    "y_test_royal = royal[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths training variables:  2634 , 2634\n",
      "lengths testing variables:  199 , 199 \n",
      "\n",
      "Are there any missing values? \n",
      " * Training: False , True \n",
      " * Testing:  False , False\n"
     ]
    }
   ],
   "source": [
    "print('lengths training variables: ', len(X_train),\",\", len(Y_train))\n",
    "print('lengths testing variables: ', len(X_test),\",\", len(Y_test), '\\n')\n",
    "\n",
    "print('Are there any missing values?', \n",
    "      '\\n * Training:', pd.isnull(X_train).values.any(), ',', pd.isnull(Y_train).values.any(), \n",
    "      '\\n * Testing: ', pd.isnull(X_test).values.any(), \",\", pd.isnull(Y_test).values.any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Transform Data to Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "xtrain = tfidf.fit_transform(X_train) # transform and fit training data\n",
    "xtest = tfidf.transform(X_test) # transform trump test data from fitted transformer\n",
    "xuser = tfidf.transform(X_user) # transform user selected comments to predict on\n",
    "\n",
    "data_trans= tfidf.transform(data[\"com_stem_str\"]) # same as X_train...transform entire dataset for cross validation\n",
    "df_trans = tfidf.transform(df[\"com_stem_str\"]) # same as X_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_videos = tfidf.fit_transform(x_train_videos)\n",
    "x_test_videos = tfidf.transform(x_test_videos)\n",
    "\n",
    "x_train_full = tfidf.fit_transform(x_train_full)\n",
    "x_test_full = tfidf.transform(x_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_not_okgo = tfidf.fit_transform(x_train_not_okgo)\n",
    "x_test_okgo = tfidf.transform(x_test_okgo)\n",
    "\n",
    "####\n",
    "x_train_not_royal = tfidf.fit_transform(x_train_not_royal)\n",
    "x_test_royal = tfidf.transform(x_test_royal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tagged = tfidf.transform(df[\"tagged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm # support vector machine\n",
    "from sklearn import metrics # for accuracy/ precision\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "lr = LogisticRegression(solver='sag', max_iter=100, random_state=42, multi_class=\"multinomial\")\n",
    "#svm = svm.SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "xgb = XGBClassifier()\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_videos = tfidf.fit_transform(x_train_videos)\\nx_test_videos = tfidf.transform(x_test_videos)\\n\\nx_train_full = tfidf.fit_transform(x_train_full)\\nx_test_full = tfidf.transform(x_test_full)\\n\\n####\\nx_train_not_okgo = tfidf.fit_transform(x_train_not_okgo)\\nx_test_not_okgo = tfidf.transform(x_test_not_okgo)\\n\\n####\\nx_train_not_royal = tfidf.fit_transform(x_train_not_royal)\\nx_test_not_royal = tfidf.transform(x_test_not_royal)\\n'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_train_videos = tfidf.fit_transform(x_train_videos)\n",
    "x_test_videos = tfidf.transform(x_test_videos)\n",
    "\n",
    "x_train_full = tfidf.fit_transform(x_train_full)\n",
    "x_test_full = tfidf.transform(x_test_full)\n",
    "\n",
    "####\n",
    "x_train_not_okgo = tfidf.fit_transform(x_train_not_okgo)\n",
    "x_test_not_okgo = tfidf.transform(x_test_not_okgo)\n",
    "\n",
    "####\n",
    "x_train_not_royal = tfidf.fit_transform(x_train_not_royal)\n",
    "x_test_not_royal = tfidf.transform(x_test_not_royal)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLpipeline(model, xtrain, xtest, ytrain, ytest):\n",
    "    model.fit(xtrain, ytrain)\n",
    "    model_predict = model.predict(xtest)\n",
    "    model_acc = metrics.accuracy_score(ytest, model_predict)\n",
    "    print('We obtained ', round(model_acc, 6), '% accuracy for the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.629459 % accuracy for the model\n",
      "We obtained  0.63061 % accuracy for the model\n",
      "We obtained  0.551208 % accuracy for the model\n",
      "We obtained  0.594937 % accuracy for the model\n",
      "We obtained  0.614499 % accuracy for the model\n"
     ]
    }
   ],
   "source": [
    "MLpipeline(mnb, x_train_videos, x_test_videos, y_train_videos, y_test_videos)\n",
    "MLpipeline(lr, x_train_videos, x_test_videos, y_train_videos, y_test_videos)\n",
    "MLpipeline(knn, x_train_videos, x_test_videos, y_train_videos, y_test_videos)\n",
    "MLpipeline(xgb, x_train_videos, x_test_videos, y_train_videos, y_test_videos)\n",
    "MLpipeline(rf, x_train_videos, x_test_videos, y_train_videos, y_test_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.500502 % accuracy for the model\n",
      "We obtained  0.512036 % accuracy for the model\n",
      "We obtained  0.461886 % accuracy for the model\n",
      "We obtained  0.519559 % accuracy for the model\n",
      "We obtained  0.535105 % accuracy for the model\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = x_train_not_okgo, x_test_okgo, y_train_not_okgo, y_test_okgo\n",
    "\n",
    "MLpipeline(mnb, a, b, c, d)\n",
    "MLpipeline(lr, a, b, c, d)\n",
    "MLpipeline(knn, a, b, c, d)\n",
    "MLpipeline(xgb, a, b, c, d)\n",
    "MLpipeline(rf, a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.837965 % accuracy for the model\n",
      "We obtained  0.870045 % accuracy for the model\n",
      "We obtained  0.820597 % accuracy for the model\n",
      "We obtained  0.847568 % accuracy for the model\n",
      "We obtained  0.861872 % accuracy for the model\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = x_train_full, x_test_full, y_train_full, y_test_full\n",
    "\n",
    "MLpipeline(mnb, a, b, c, d)\n",
    "MLpipeline(lr, a, b, c, d)\n",
    "MLpipeline(knn, a, b, c, d)\n",
    "MLpipeline(xgb, a, b, c, d)\n",
    "MLpipeline(rf, a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.655738 % accuracy for the model\n",
      "We obtained  0.639344 % accuracy for the model\n",
      "We obtained  0.540984 % accuracy for the model\n",
      "We obtained  0.639344 % accuracy for the model\n",
      "We obtained  0.655738 % accuracy for the model\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = x_train_not_royal, x_test_royal, y_train_not_royal, y_test_royal\n",
    "\n",
    "MLpipeline(mnb, a, b, c, d)\n",
    "MLpipeline(lr, a, b, c, d)\n",
    "MLpipeline(knn, a, b, c, d)\n",
    "MLpipeline(xgb, a, b, c, d)\n",
    "MLpipeline(rf, a, b, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # frequency counts matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint, expon, uniform\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, Y_train, Y_test = train_test_split(\n",
    "    videos[\"comment\"], videos[\"label\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 696 ms, sys: 752 ms, total: 1.45 s\n",
      "Wall time: 6.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb_param_distribs = {\n",
    "    'clf__alpha': [1,0.5,0.3,0.1,0.01,0.001,0],\n",
    "    }\n",
    "\n",
    "mnb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', MultinomialNB())\n",
    "               ])\n",
    "\n",
    "mnb_search = GridSearchCV(mnb,\n",
    "                        param_grid=mnb_param_distribs,\n",
    "                        n_jobs=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        )\n",
    "\n",
    "\n",
    "mnb_search.fit(xtrain, Y_train) # fit the model on the training data word counts and training data lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Predictions:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.660529 % accuracy for the model\n"
     ]
    }
   ],
   "source": [
    "mnb_predict = mnb_search.predict(xtest) # make our y predictions (labels) on the comment test data\n",
    "mnb_acc = metrics.accuracy_score(Y_test, mnb_predict)\n",
    "print('We obtained ', round(mnb_acc, 6), '% accuracy for the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.71      0.39      0.50       200\n",
      "        0.0       0.63      0.79      0.70       386\n",
      "        1.0       0.70      0.67      0.69       283\n",
      "\n",
      "avg / total       0.67      0.66      0.65       869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, mnb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78,  95,  27],\n",
       "       [ 27, 305,  54],\n",
       "       [  5,  87, 191]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, mnb_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation of Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.59 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mnb, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 632 ms, sys: 716 ms, total: 1.35 s\n",
      "Wall time: 4.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_param_distribs = {\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    }\n",
    "\n",
    "lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', LogisticRegression(solver='sag', \n",
    "                                           max_iter=100, \n",
    "                                           random_state=42, \n",
    "                                           multi_class=\"multinomial\")) # set multinomial setting for multiclass data\n",
    "               ])\n",
    "\n",
    "lr_search = GridSearchCV(lr,\n",
    "                        param_grid=lr_param_distribs,\n",
    "                        n_jobs=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        )\n",
    "\n",
    "lr_search.fit(xtrain, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.660529 % accuracy for the logistic regression model\n"
     ]
    }
   ],
   "source": [
    "lr_predict = lr_search.predict(xtest)\n",
    "lr_acc = metrics.accuracy_score(Y_test, lr_predict)\n",
    "print('We obtained ', round(lr_acc, 6), '% accuracy for the logistic regression model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.66      0.41      0.50       200\n",
      "        0.0       0.60      0.83      0.70       386\n",
      "        1.0       0.80      0.60      0.69       283\n",
      "\n",
      "avg / total       0.68      0.66      0.65       869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82, 104,  14],\n",
       "       [ 37, 321,  28],\n",
       "       [  6, 106, 171]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.61 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Model & Predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 0 ns, total: 3min 20s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_param_distribs = {\n",
    "    'clf__C': expon(scale=100), \n",
    "    'clf__gamma': expon(scale=.1),\n",
    "    'clf__class_weight':['balanced', None]\n",
    "    }\n",
    "\n",
    "svm = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', SVC())\n",
    "               ])\n",
    "\n",
    "svm_search = RandomizedSearchCV(svm,\n",
    "                        param_distributions=svm_param_distribs,\n",
    "                        n_iter=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        random_state=42)\n",
    "\n",
    "svm_search.fit(xtrain, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.653625 % accuracy for the SVM model\n"
     ]
    }
   ],
   "source": [
    "svm_predict = svm_search.predict(xtest)\n",
    "svm_acc = metrics.accuracy_score(Y_test, svm_predict)\n",
    "print('We obtained ', round(svm_acc, 6), '% accuracy for the SVM model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.82      0.21      0.33       200\n",
      "        0.0       0.57      0.89      0.69       386\n",
      "        1.0       0.79      0.59      0.68       283\n",
      "\n",
      "avg / total       0.70      0.64      0.61       869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, mnb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82, 104,  14],\n",
       "       [ 37, 321,  28],\n",
       "       [  6, 106, 171]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Y_test, lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.44 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting Model & Predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN ensemble method\n",
    "\n",
    "knn_param_distribs = {\n",
    "    'clf__n_neighbors': randint(low=1,high=100), \n",
    "    }\n",
    "\n",
    "knn = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', KNeighborsClassifier())\n",
    "               ])\n",
    "\n",
    "knn_search = RandomizedSearchCV(knn,\n",
    "                        param_distributions=knn_param_distribs,\n",
    "                        n_iter=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.524741 % accuracy for the KNN Bagging model\n"
     ]
    }
   ],
   "source": [
    "knn_search.fit(xtrain, Y_train)\n",
    "\n",
    "knn_predict = knn_search.predict(xtest)\n",
    "knn_acc = metrics.accuracy_score(Y_test, knn_predict)\n",
    "print('We obtained ', round(knn_acc, 6), '% accuracy for the KNN Bagging model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.48 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(knn, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting Model & Predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.537688 % accuracy for the Random Forest model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # random forest ensemble method\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "ranfor = ranfor.fit(xtrain, Y_train)\n",
    "\n",
    "rf_predict = ranfor.predict(xtest)\n",
    "rf_acc = metrics.accuracy_score(Y_test, rf_predict)\n",
    "print('We obtained ', round(rf_acc, 6), '% accuracy for the Random Forest model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.45 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ranfor, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Pipeline - transformations, grid search, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 56s, sys: 44.5 s, total: 5min 40s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_param_distribs = {\n",
    "    'clf__n_estimators': randint(low=1, high=700),\n",
    "    'clf__max_features': randint(low=1, high=20),\n",
    "    'clf__max_depth': randint(low=1, high=30),\n",
    "    'clf__min_samples_split': randint(low=2, high=150)\n",
    "    }\n",
    "\n",
    "rf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', RandomForestClassifier(random_state=42,\n",
    "                                              n_jobs=-1,\n",
    "                                              class_weight='balanced'))\n",
    "               ])\n",
    "\n",
    "rf_search = RandomizedSearchCV(rf,\n",
    "                        param_distributions=rf_param_distribs,\n",
    "                        n_iter=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        random_state=42)\n",
    "\n",
    "rf_search.fit(xtrain, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.623705 % accuracy for the Random Forest model\n"
     ]
    }
   ],
   "source": [
    "rf_predict = rf_search.predict(xtest)\n",
    "rf_acc = metrics.accuracy_score(Y_test, rf_predict)\n",
    "print('We obtained ', round(rf_acc, 6), '% accuracy for the Random Forest model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.637514 % accuracy for the Random Forest model\n"
     ]
    }
   ],
   "source": [
    "rf_predict = rf_search.predict(xtest)\n",
    "rf_acc = metrics.accuracy_score(Y_test, rf_predict)\n",
    "print('We obtained ', round(rf_acc, 6), '% accuracy for the Random Forest model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.482412 % accuracy for the XGB Bagging model\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(xtrain, Y_train)\n",
    "xgb_pred = xgb.predict(xtest)\n",
    "xgb_acc = metrics.accuracy_score(Y_test, xgb_pred)\n",
    "print('We obtained ', round(xgb_acc, 6), '% accuracy for the XGB Bagging model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Accuracy: 0.57 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb, xtest, Y_test, cv=5) # 5 fold cross validation\n",
    "print(\"Confidence Interval for Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "%%time\n",
    "\n",
    "gb_param_distribs = {\n",
    "    'clf__max_depth': randint(3,10),\n",
    "    'clf__min_child_weight': randint(1,12),\n",
    "    'clf__max_depth': randint(low=2, high=8),\n",
    "    'clf__gamma': [i/10.0 for i in range(0,5)],\n",
    "    'clf__subsample':[i/10.0 for i in range(6,10)],\n",
    "    'clf__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'clf__reg_alpha': [0, 0.001, 0.005, 0.01, 0.05]\n",
    "    }\n",
    "\n",
    "gb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', XGBClassifier(random_state=42)\n",
    "               ])\n",
    "\n",
    "gb_search = RandomizedSearchCV(gb,\n",
    "                        param_distributions=gb_param_distribs,\n",
    "                        n_iter=50,\n",
    "                        cv=5,\n",
    "                        #scoring='roc_auc',\n",
    "                        random_state=42)\n",
    "\n",
    "gb_search.fit(xtrain, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models as pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf.pkl']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb_search, 'mnb.pkl')\n",
    "joblib.dump(lr_search, 'lr.pkl')\n",
    "joblib.dump(svm_search, 'svm.pkl')\n",
    "joblib.dump(knn_search, 'knn.pkl')\n",
    "joblib.dump(rf_search, 'rf.pkl')\n",
    "#joblib.dump(gb_search, 'gb.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavedData = open(\"pickled_material/data.pickle\",\"wb\")\n",
    "pickle.dump(documents, SavedData)\n",
    "SavedData.close()\n",
    "\n",
    "SavedFeatures = open(\"pickled_material/SavedFeatures.pickle\",\"wb\")\n",
    "pickle.dump(word_features, SavedFeatures)\n",
    "SavedFeatures.close()\n",
    "\n",
    "SavedModels= open(\"pickled_material/SavedModels.pickle\",\"wb\")\n",
    "pickle.dump(models, SavedModels)\n",
    "SavedModels.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Table of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Support Vect Machine</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>K-NN</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.477387</td>\n",
       "      <td>0.437186</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.537688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Naive Bayes  Support Vect Machine  Logistic Regression      K-NN  \\\n",
       "Accuracy     0.477387              0.437186             0.507538  0.432161   \n",
       "\n",
       "          Random Forest  \n",
       "Accuracy       0.537688  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTable = pd.DataFrame(columns=['Naive Bayes','Support Vect Machine','Logistic Regression', 'K-NN', 'Random Forest'],\n",
    "                   index=[\"Accuracy\"])\n",
    "myTable['Naive Bayes']=mnb_acc; myTable['Support Vect Machine']=svm_acc; myTable['Logistic Regression']=lr_acc\n",
    "myTable['K-NN']= knn_acc; myTable['Random Forest']= rf_acc\n",
    "myTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
